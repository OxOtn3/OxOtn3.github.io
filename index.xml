<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>耶宵夜</title>
        <link>https://example.com/</link>
        <description>Recent content on 耶宵夜</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Fri, 25 Mar 2022 22:19:50 +0800</lastBuildDate><atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Cuckoo Filter</title>
        <link>https://example.com/p/cuckoo-filter/</link>
        <pubDate>Fri, 25 Mar 2022 22:19:50 +0800</pubDate>
        
        <guid>https://example.com/p/cuckoo-filter/</guid>
        <description>&lt;p&gt;&lt;em&gt;前言&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;逛GitHub的时候看到了&lt;a class=&#34;link&#34; href=&#34;https://github.com/CDDSCLab/training-plan&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这个repo&lt;/a&gt;，里面提到了Cuckoo Filter，没听说过，学习一下，顺便做个笔记持久化。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;实际上源于2014年CMU的一篇论文：&lt;a class=&#34;link&#34; href=&#34;https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cuckoo Filter: Practically Better Than Bloom&lt;/a&gt;，听名字就知道，和布隆过滤器类似。&lt;/p&gt;
&lt;h3 id=&#34;什么是cuckoo-filter&#34;&gt;什么是Cuckoo Filter&lt;/h3&gt;
&lt;p&gt;论文摘要：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In many networking systems, Bloom filters are used for highspeed set membership tests. They permit a small fraction of false positive answers with very good space efficiency. However, &lt;strong&gt;they do not permit deletion of items from the set&lt;/strong&gt;, and previous attempts to extend “standard” Bloom filters to support deletion all &lt;strong&gt;degrade either space or performance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We propose a new data structure called the &lt;strong&gt;cuckoo filter&lt;/strong&gt; that can replace Bloom filters for approximate set membership tests. Cuckoo filters &lt;strong&gt;support adding and removing items dynamically while achieving even higher performance&lt;/strong&gt; than Bloom filters. For applications that store many items and target moderately low false positive rates, cuckoo filters have lower space overhead than space-optimized Bloom filters. Our experimental results also show that cuckoo filters outperform previous data structures that extend Bloom filters to support deletions substantially in both time and space.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说就是解决了Bloom Filter不能删除，或者删除影响空间或时间上的性能的问题。Cuckoo Filter在解决这一问题的同时，还能够表现出更好的性能。（吹是这么吹的）&lt;/p&gt;
&lt;p&gt;在合适的参数配置下，空间利用率可以达到95%。&lt;/p&gt;
&lt;h3 id=&#34;为什么叫cuckoo-filter&#34;&gt;为什么叫Cuckoo Filter&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Cuckoo&lt;/code&gt; 的意思是 &lt;code&gt;布谷鸟&lt;/code&gt; ，取这个名字其实跟他的算法实现有关。&lt;/p&gt;
&lt;p&gt;看一张论文里的图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/cuckoo_hashing.png&#34;
	width=&#34;1558&#34;
	height=&#34;606&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/cuckoo_hashing_hu47387e887ccc95c3501cbfc7667701db_124475_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/cuckoo_hashing_hu47387e887ccc95c3501cbfc7667701db_124475_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Cuckoo Hashing&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;257&#34;
		data-flex-basis=&#34;617px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看到每个item会有两个 &lt;code&gt;candidate buckets&lt;/code&gt; ，如果有任意一个是空的，直接插入即可；如果都已经被占了，则会&lt;strong&gt;任意&lt;/strong&gt;挑选出一个bucket，把其中的元素移出来，再将这个 &lt;code&gt;victim&lt;/code&gt; 插入到其他可供选择的地方。&lt;/p&gt;
&lt;p&gt;这个过程会一直重复到能找到一个空的bucket，或者替换次数达到一个阈值（原文为500次）。&lt;/p&gt;
&lt;p&gt;尽管Cuckoo Hashing可能会引起一系列的替换，但是这个操作的均摊时间复杂度是O(1)。&lt;/p&gt;
&lt;p&gt;回到名字上来，这个过程其实和布谷鸟下蛋很像。&lt;/p&gt;
&lt;p&gt;布谷鸟会把蛋下到别的鸟的巢里，而布谷鸟的幼鸟比别的鸟出生的早，于是会将别的还没出生的鸟蛋挤出巢外，来保证自己今后能独享食物。&lt;/p&gt;
&lt;p&gt;懂了之后就会感觉这个命名确实很生动，也让人不禁想到Kafka中一系列有趣的命名。计算机科学家还是很有意思的。&lt;/p&gt;
&lt;p&gt;另外，(c) 图中展示的是优化过后的hash table，可以看到一个bucket中有4个entry，很大程度上减少了冲突几率。&lt;/p&gt;
&lt;h2 id=&#34;优化&#34;&gt;优化&lt;/h2&gt;
&lt;p&gt;如果只根据标准的Cuckoo hashing方法计算冲突时可选的空间，（原文中说）一个很容易想到的方法是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;store each inserted item in its entirety (perhaps externally to the table); given the original item (“key”), calculating its alternate location is easy&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我的理解就是，对于每一个插入的item，都维护一个变量（可以看作是这个item的entirety），这个变量记录了这个item所有可能的index值，然后再对key进行计算。重点在于维护这个变量需要的在hash table之外的&lt;strong&gt;额外空间&lt;/strong&gt;，会产生比较大的开销。&lt;/p&gt;
&lt;p&gt;为了达到更好的空间上的效率，减少hash table以外的大小，提出了下面的优化。&lt;/p&gt;
&lt;h3 id=&#34;partial-key-cuckoo-hashing&#34;&gt;partial-key cuckoo hashing&lt;/h3&gt;
&lt;p&gt;每一个item都根据一个常数大小的 &lt;code&gt;fingerprint&lt;/code&gt; 进行hash。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么这个fingerprint也需要额外空间，刚才的entirety也需要额外空间，就算成优化了呢？其实很简单，因为fingerprint相较于entirety需要的空间开销更小，是常数级别的。并且在后面可以看到，对于大部分数据，4~5bit大小的fingerprint就能够达到非常好的空间占用率。而如果采用entirety，在下面的算法实现中可以看到，对于每一个bucket计算出备选bucket的index时，还需要回溯(retrieve)出该bucket的值，而采用fingerprint就可以避免这一操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;算法实现&#34;&gt;算法实现&lt;/h2&gt;
&lt;p&gt;主要是三部分：插入、查询和删除。&lt;/p&gt;
&lt;h3 id=&#34;插入&#34;&gt;插入&lt;/h3&gt;
&lt;p&gt;先看下原文的伪代码实现：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/insert.png&#34;
	width=&#34;1036&#34;
	height=&#34;936&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/insert_huafcab5030055f94c3e47a71edb150854_143137_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/insert_huafcab5030055f94c3e47a71edb150854_143137_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;insert-伪代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;110&#34;
		data-flex-basis=&#34;265px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，计算i2的时候用到了i1和hash(f)的异或，这是很方便也很有必要的，因为这样一来，就可以保证i1也可以用同样的方式通过i2和hash(f)计算得出。所以，当我们需要计算出当前bucket的备选bucket时，只需要根据当前bucket的下标i以及存在bucket中的fingerprint得到备选目标j，即：&lt;/p&gt;
&lt;p&gt;$$j = i\oplus hash(fingerprint)$$&lt;/p&gt;
&lt;p&gt;这样一来，每次插入实际上只用到了表内的信息，不需要追溯到原来的item。&lt;/p&gt;
&lt;p&gt;并且可以看到，在每次异或运算前对fingerprint进行hash而不是之后，目的也是为了减少冲突，否则如果先异或后hash，很容易落到临近的bucket中。&lt;/p&gt;
&lt;p&gt;此外，如果两个或多个item具有相同的fingerprint，也是可以的，但有一个上限 &lt;code&gt;2b&lt;/code&gt; ，b为bucket的大小，此时这些重复的item的两个bucket将会变得超载。&lt;/p&gt;
&lt;p&gt;循环中 &lt;code&gt;MaxNumKicks&lt;/code&gt; 其实就是最大重试次数，比如500次，如果超过这个次数还没有成功插入，就可以认为这个table满了。&lt;/p&gt;
&lt;p&gt;并且也可以看到，通过 &lt;code&gt;partial-key&lt;/code&gt; 的优化，现在每次冲突时计算备选空间地址，无论冲突了多少次，只需要根据fingerprint，还是很方便的。&lt;/p&gt;
&lt;h3 id=&#34;查询&#34;&gt;查询&lt;/h3&gt;
&lt;p&gt;伪代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/lookup.png&#34;
	width=&#34;1022&#34;
	height=&#34;414&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/lookup_hu60cb88140d1a98b7e3a322bbbbd5fd53_52523_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/lookup_hu60cb88140d1a98b7e3a322bbbbd5fd53_52523_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;lookup-伪代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;删除&#34;&gt;删除&lt;/h3&gt;
&lt;p&gt;伪代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/delete.png&#34;
	width=&#34;1024&#34;
	height=&#34;446&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/delete_hu071bd94d923ff16b665f3e678e2917cd_60911_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/delete_hu071bd94d923ff16b665f3e678e2917cd_60911_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;delete-伪代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;229&#34;
		data-flex-basis=&#34;551px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;删除操作思路很简单，判断一下两个桶有没有相符的fingerprint，有就删除。这里的删除也不是真的把数据删除，而只是简单的标记一下。&lt;/p&gt;
&lt;h2 id=&#34;效果&#34;&gt;效果&lt;/h2&gt;
&lt;p&gt;简单的看下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/load-factor.png&#34;
	width=&#34;2214&#34;
	height=&#34;1012&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/load-factor_hu492471baf84afe3062376e79d1ee2c7b_315168_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/load-factor_hu492471baf84afe3062376e79d1ee2c7b_315168_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;bucket size为4和8情况下 load factor和fingerprint size关系图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;218&#34;
		data-flex-basis=&#34;525px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;这里就援引论文中的Conclusion：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Cuckoo filters are a new data structure for approximate set membership queries that can be used for many networking problems formerly solved using Bloom filters. Cuckoo filters improve upon Bloom filters in three ways: (1) &lt;strong&gt;support for deleting items dynamically&lt;/strong&gt;; (2) &lt;strong&gt;better lookup performance&lt;/strong&gt;; and (3) &lt;strong&gt;better space efficiency for applications requiring low false positive rates&lt;/strong&gt; (&amp;lt; 3%). A cuckoo filter stores the fingerprints of a set of items based on cuckoo hashing, thus achieving high space occupancy. As a further key contribution, we have applied &lt;strong&gt;partial-key&lt;/strong&gt; cuckoo hashing, which makes cuckoo filters significantly more efficient by allowing relocation based on &lt;strong&gt;only the stored fingerprint&lt;/strong&gt;. Our configuration exploration suggests that the cuckoo filter, which uses buckets of size 4, will perform well for a wide range of applications, although appealingly cuckoo filter parameters can be easily varied for application-dependent tuning.&lt;/p&gt;
&lt;p&gt;While we expect that further extensions and optimizations to cuckoo filters are possible and will further provide impetus for their use, the data structure as described is a fast and efficient building block already well-suited to the practical demands of networking and distributed systems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;几个重点也都加粗了，主要是相比于Bloom Filter的三大优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持动态删除&lt;/li&gt;
&lt;li&gt;查询性能更好&lt;/li&gt;
&lt;li&gt;空间效率更高&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;并且经过 &lt;code&gt;partial-key&lt;/code&gt; 的优化，对于每一个item，只需要额外存储 &lt;code&gt;fingerprint&lt;/code&gt; 的值作为hash的依据，节省空间开销。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>《凤凰架构》读书笔记（1）</title>
        <link>https://example.com/p/fenix_arch_book_1/</link>
        <pubDate>Fri, 11 Mar 2022 15:07:15 +0800</pubDate>
        
        <guid>https://example.com/p/fenix_arch_book_1/</guid>
        <description>&lt;h2 id=&#34;第1章-服务架构演进史&#34;&gt;第1章 服务架构演进史&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;架构并不是被发明出来的，而是持续演进的结果&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;2 Pizza Team&lt;/code&gt;: 衡量团队大小的量词，指两个Pizza能喂饱的人数，挺有意思&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;单体系统的真正缺陷不在如何拆分，而在&lt;strong&gt;拆分之后的自治与隔离能力&lt;/strong&gt;上。由于所有代码都运行在同一个进程内，所有模块、方法的调用都无须考虑&lt;strong&gt;网络分区&lt;/strong&gt;、&lt;strong&gt;对象复制&lt;/strong&gt;这些麻烦的事。&lt;/p&gt;
&lt;p&gt;但在获得进程内调用的简单和高效的同时，也意味着一部分代码出现了缺陷，将会过度消耗进程空间内的资源，造成的影响也会是全局性、难以隔离的，例如&lt;strong&gt;内存泄漏&lt;/strong&gt;、&lt;strong&gt;线程爆炸&lt;/strong&gt;、&lt;strong&gt;阻塞&lt;/strong&gt;、&lt;strong&gt;死循环&lt;/strong&gt;等问题。如果出现问题的是某些更高层次的公共资源，例如端口号和数据库连接池泄漏，还会影响整台机器，乃至集群中其他单体副本的正常工作。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;code&gt;SOA&lt;/code&gt;: Service-Oriented Architecture，面向服务架构，三种代表性的架构模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;烟囱式架构（信息孤岛）&lt;/li&gt;
&lt;li&gt;微内核架构（插件式架构）&lt;/li&gt;
&lt;li&gt;事件驱动架构&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SOAP协议被边缘化的本质原因：&lt;strong&gt;过于严格的规范定义带来过度复杂性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;&amp;gt; ==我的理解==：和OSI7层模型很像，是一种很好的思想，但实际中用到的往往是简化版的，例如5层，TCP/IP协议簇的4层&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;微服务的概念：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言、不同的存储技术，运行在不同的进程之中。服务采用轻量级的通信机制和自动化的部署机制实现通信与运维。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“微服务时代充满着自由的气息，微服务时代充斥着迷茫的选择。”&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;服务网格&lt;/strong&gt;(Service Mesh)的&lt;strong&gt;边车代理模式&lt;/strong&gt;(Sidecar Proxy)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/fenix_arch_book_1/sidecar_proxy.png&#34;
	width=&#34;1622&#34;
	height=&#34;952&#34;
	srcset=&#34;https://example.com/p/fenix_arch_book_1/sidecar_proxy_hu099d5a05ea85ba71ecf5339ce342528d_363902_480x0_resize_box_3.png 480w, https://example.com/p/fenix_arch_book_1/sidecar_proxy_hu099d5a05ea85ba71ecf5339ce342528d_363902_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;边车代理&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;408px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在虚拟化场景中的边车指，由系统自动在服务容器（通常是k8s的pod）中注入一个&lt;strong&gt;通信代理服务器&lt;/strong&gt;，以类似中间人攻击的方式进行流量劫持，在应用无感知的情况下接管通信。&lt;/p&gt;
&lt;p&gt;这个代理除了实现正常的服务通信外（称为数据平面通信），还接收来自控制器的指令（控制平面通信），根据控制平面中的配置，对数据平面通信的内容进行分析处理，从而实现熔断、认证、度量、监控、负载均衡等各种附加功能。&lt;/p&gt;
&lt;p&gt;通过边车代理模式，既不需要在应用层加入额外的处理代码，也提供了几乎不亚于程序代码的精细管理能力。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Serverless的两大内容&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;后端设施&lt;/strong&gt;(Backend)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;指数据库、消息队列、日志、存储等这类用于支撑业务逻辑运行，但本身无业务含义的技术组件&lt;/p&gt;
&lt;p&gt;这些后端设施都运行在云中，在serverless中称为Baas(Backend as a Service)&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;函数&lt;/strong&gt;(Function)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;指业务逻辑代码，很接近程序编码角度的函数，区别在于serverless中的函数运行在云端，不必考虑算力和容量规划，称为FaaS(Function ..)&lt;/p&gt;
&lt;p&gt;无服务架构确实能降低一些应用的开发和运维成本，例如不需要交互的离线大规模计算，或者Web资讯类网站、小程序、公共API服务、移动应用服务端等契合于无服务架构所擅长的短链接、无状态、适合事件驱动的交互方式。&lt;/p&gt;
&lt;p&gt;但另一方面，对于诸如信息管理系统、网络游戏等，或说对具有业务逻辑复杂、依赖服务端状态、响应速度要求较高、需要长链接等特征的应用，至少目前不是那么合适。&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;如果说微服务架构是分布式系统这条路当前所能做到的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;软件开发的最大挑战就在于只能在不完备的信息下决定当前要处理的问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;We can only see a short distance ahead, but we can see plenty there that needs to be done.&lt;/p&gt;
&lt;p&gt;&amp;ndash;Alan Turing&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>NAT详解</title>
        <link>https://example.com/p/nat%E8%AF%A6%E8%A7%A3/</link>
        <pubDate>Sun, 06 Mar 2022 17:31:19 +0800</pubDate>
        
        <guid>https://example.com/p/nat%E8%AF%A6%E8%A7%A3/</guid>
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;还记得一个月前被面试官问到NAT的时候完全茫然，面试结束复盘的时候发现自己一直在用的内网穿透APP就是基于NAT的。平时还是得多问问为什么。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;在介绍NAT之前，首先需要简单介绍一下防火墙。&lt;/p&gt;
&lt;h2 id=&#34;防火墙&#34;&gt;&lt;strong&gt;防火墙&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;防火墙简介&#34;&gt;防火墙简介&lt;/h3&gt;
&lt;p&gt;防火墙的任务是&lt;strong&gt;控制互联网中网络流量的流向&lt;/strong&gt;，本质上是一种&lt;strong&gt;能够限制转发流量类型的路由器&lt;/strong&gt;。（代理防火墙严格意义上不算是）&lt;/p&gt;
&lt;p&gt;常见的防火墙主要有两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;包过滤防火墙（packet-filter firewall）&lt;/li&gt;
&lt;li&gt;代理防火墙（proxy firewall）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包过滤防火墙是一个互联网路由器，能够根据条件对数据包进行丢弃/传输的操作。而代理防火墙是一个服务器主机，它作为TCP和UDP传输的一个端点，通常不会在IP协议层中路由IP数据包。&lt;/p&gt;
&lt;p&gt;二者的主要区别是&lt;strong&gt;所操作的协议栈的层次不同&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;包过滤防火墙&#34;&gt;包过滤防火墙&lt;/h3&gt;
&lt;p&gt;过滤器选项包括：IP地址、ICMP报文类型、数据包中的端口号等。&lt;/p&gt;
&lt;p&gt;包过滤防火墙可分为&lt;strong&gt;无状态的&lt;/strong&gt;和&lt;strong&gt;有状态的&lt;/strong&gt;。无状态的包过滤防火墙单独处理每一个数据包；而有状态的防火墙能够通过关联已经或者即将到达的数据包来推断数据信息。（举个例子，对于分片的IP报文，有状态的防火墙往往能够判断出其属于同一个IP数据报，但无状态的无法做到）&lt;/p&gt;
&lt;h3 id=&#34;代理防火墙&#34;&gt;代理防火墙&lt;/h3&gt;
&lt;p&gt;代理防火墙的本质是运行一个或多个应用层网关的主机。&lt;/p&gt;
&lt;p&gt;一般来说，防火墙内的客户端通常会进行特殊配制，从而能够连接到代理防火墙，而不是连接到真正提供服务的主机。所以说这种防火墙配置繁琐（必须为每个传输层服务设置一个代理，通过这个代理和新的服务器发起连接）。但也正因如此，代理防火墙是非常安全的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我的理解中，这是一种用配置的繁琐换安全性的trade-off。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;常见的代理防火墙的形式有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP代理防火墙&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也称为Web代理，只能用于HTTP和HTTPS协议。这种代理对于内网用户来说相当于Web服务器，对于被访问的外部网站来说相当于Web客户端。&lt;/p&gt;
&lt;p&gt;此外，这种代理往往还提供其他的一些功能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Web缓存功能。对网页内容进行缓存，从而减少网页延迟，提高用户访问体验。（例如HTTP缓存）&lt;/li&gt;
&lt;li&gt;作为内容过滤器，基于黑名单屏蔽特定用户。&lt;/li&gt;
&lt;li&gt;隧道代理服务器，功能和2相反。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;SOCKS代理防火墙&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比于HTTP代理，范围更广，可以用于Web以外的其他服务。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;nat网络地址转换&#34;&gt;NAT网络地址转换&lt;/h2&gt;
&lt;h3 id=&#34;基本概念&#34;&gt;基本概念&lt;/h3&gt;
&lt;p&gt;书上关于NAT的基本概念这一块个人认为解释的非常清楚，直接拿来：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NAT(Network Address Translation)&lt;strong&gt;本质&lt;/strong&gt;上是一种允许在互联网不同地方重复使用相同的IP地址集的机制。建立NAT的&lt;strong&gt;主要动机&lt;/strong&gt;是正在急剧减少的有限IP地址空间。使用NAT&lt;strong&gt;最常见的情况&lt;/strong&gt;是，唯一与Internet连接的站点仅被分配了很少的几个IP地址（甚至只有一个IP地址），但是内部却有多台主机需要同时上网。当所有进出的流量均通过一个单独的NAT设备时，该设备将内部系统的地址空间和全球互联网地址空间分割开，因此所有的内部系统可以使用本地分配的私有IP地址访问互联网。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;NAT的工作原理是&lt;strong&gt;重写通过路由器数据包的识别信息&lt;/strong&gt;，并且大多数的NAT同时进行地址转换和包过滤。&lt;/p&gt;
&lt;p&gt;引入NAT其实一开始主要为了解决两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP地址不够用&lt;/li&gt;
&lt;li&gt;路由可扩展性不强&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，&lt;strong&gt;CIDR&lt;/strong&gt;的发展比较好的解决了后一个问题。（书上是这么描述的，但我觉得这两个问题归根结底是一个问题。可能书上想表达的意思是，路由可扩展性不强，是由于5种IP地址种类已经定死了，无法再修改，而CIDR解决了这个问题；而IP地址不够用，是因为在IP地址定死了，不可变，我们不去考虑IP地址分类的前提条件下，一个IP只能对应一个地址，不能被复用）&lt;/p&gt;
&lt;p&gt;NAT也一定程度上缓解了前一个问题。但是NAT毕竟只是权宜之计，真正解决第一个问题还是得用IPv6，但是又因为NAT发展的太好了，使用的人太多了，反而拖延了IPv6的推进。&lt;/p&gt;
&lt;p&gt;对于NAT，也有很多其他的缺点，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果想要让NAT内部的主机能够被访问，必须进行特殊配置，因为互联网上的用户无法直接访问私有地址的主机&lt;/li&gt;
&lt;li&gt;为了让NAT正常工作，每一个属于同一个连接或者关联的双向数据包都必须通过相同的NAT，因为NAT必须重写每个数据包的寻址信息，从而双方正常通信。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;传统nat基本nat和napt&#34;&gt;传统NAT：基本NAT和NAPT&lt;/h3&gt;
&lt;p&gt;传统的基本的NAT只执行对IP地址的重写，实际上这种NAT没什么用，因为需要的还是相同数量的IP地址。一个更好的做法是NAPT，NAPT使用传输层标识符（也就是TCP和UDP的端口）来确定一个特定的数据包到底和NAT内部的哪台私有主机关联。这样一来只需要很少的公有地址就可以让大量的内部主机访问公网。&lt;/p&gt;
&lt;p&gt;需要注意的一点是，如果私有范围使用的全局地址空间和另一个互联网上的实体冲突时，请求可能无法到达该地址，因为采用相同地址的本地系统会屏蔽掉使用相同地址的远端系统。为了避免这种情况发生，RFC1918中保留了3个IPv4的地址，专门做为私有地址范围：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10.0.0.0/8&lt;/li&gt;
&lt;li&gt;172.16.0.0/12&lt;/li&gt;
&lt;li&gt;192.168.0.0/16&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也就是说，不会有以以上三个地址作为公网地址出现。&lt;/p&gt;
&lt;p&gt;对于NAPT，又可分为两种：&lt;/p&gt;
&lt;h4 id=&#34;对称型nat-symmetric&#34;&gt;对称型NAT (Symmetric)&lt;/h4&gt;
&lt;p&gt;对每个外部主机或端口的会话都会映射为不同的端口。&lt;/p&gt;
&lt;h4 id=&#34;圆锥型natcone&#34;&gt;圆锥型NAT(Cone)&lt;/h4&gt;
&lt;p&gt;圆锥型NAT又可细分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完全圆锥型NAT(Full Cone)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IP和端口都不受限&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;地址限制圆锥型(Address Restricted Cone)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IP受限，端口不受限&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;端口限制圆锥型(Port Restricted Cone)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;端口限，IP不受限&lt;/p&gt;
&lt;h3 id=&#34;发夹和nat环回&#34;&gt;发夹和NAT环回&lt;/h3&gt;
&lt;p&gt;对于这个问题，书上是这样描述的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假设主机X1试图建立一个到主机X2的连接。如果X1知道私有地址信息，X2:x2，这没有任何问题，因为可以直接进行连接。然而，在某些情况下X1只知道公用地址信息，X2&#39;:x2&#39;。在这些情况下，X1借助NAT采用目的地址X2&#39;:x2&amp;rsquo;尝试连接X2。当NAT意识到X2&#39;:x2&amp;rsquo;和X2:x2之间存在映射，并将数据包转发到位于NAT私有地址空间内的X2:x2时，会触发发夹过程。此时会出现一个问题，目的是X2:x2的数据报头部中的源地址应该是X1:x1还是X1&#39;:x1&#39;？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实问题就一句话：&lt;strong&gt;在只知道公用地址的前提下，对于内网中的数据包发送的源地址应该用内网地址还是公网地址？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果NAT给X2的数据包的源地址信息是X1&#39;:x1&#39;，即公有地址，那么这种NAT被称为有“外部源ID地址和端口”的发夹行为。之所以需要这种行为，是为了均采用全局路由地址的应用能够识别对方。（我的理解是，这相当于给内网地址披了一层皮，因为X2的逻辑可能是处理外网地址的请求，这样以来实现了&lt;strong&gt;规格化&lt;/strong&gt;。有点类似于&lt;strong&gt;IP隧道技术&lt;/strong&gt;。）&lt;/p&gt;
&lt;p&gt;还有一个比较有意思的地方是，为什么这种行为叫做**发夹(hairpinning)**呢？一开始没理解，于是上网搜了一下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/nat%E8%AF%A6%E8%A7%A3/hairpin.png&#34;
	width=&#34;1602&#34;
	height=&#34;532&#34;
	srcset=&#34;https://example.com/p/nat%E8%AF%A6%E8%A7%A3/hairpin_hu8aea337501150dec4cb4eb45a6fc1d8e_215067_480x0_resize_box_3.png 480w, https://example.com/p/nat%E8%AF%A6%E8%A7%A3/hairpin_hu8aea337501150dec4cb4eb45a6fc1d8e_215067_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Hairpin&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;301&#34;
		data-flex-basis=&#34;722px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;看完这个解释，再结合具体的例子，hairpinning这个名字起的还真挺形象的。&lt;/p&gt;
&lt;h3 id=&#34;nat穿越&#34;&gt;NAT穿越&lt;/h3&gt;
&lt;p&gt;为了解决外网无法主动向内网建立连接的问题，主要通过&lt;strong&gt;NAT转换表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在NAT内侧主机上运行的应用先发送一个虚拟的网络包给NAT外侧，而NAT不知道这个包内容究竟是什么，会正常读取包首部信息，并生成一个转换表。这时，如果转换表构造合理，NAT外侧的主机就可以和内侧主机建立连接并通信。&lt;/p&gt;
&lt;p&gt;比较常见的会话穿越技术有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;STUN(Session Traversal Utilities for NAT)，能够在多种环境中确定在NAT中使用的外部IP地址和端口号，也可以通过保持激活的信息来维持当前的NAT绑定。&lt;/li&gt;
&lt;li&gt;TURN(Traversal Using Relays around NAT)，将所有的数据交换都经由服务器来完成，这样NAT将没有障碍，但会造成服务器的负载、丢包、延迟问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;包过滤防火墙和nat&#34;&gt;包过滤防火墙和NAT&lt;/h2&gt;
&lt;h3 id=&#34;包过滤防火墙配置规则&#34;&gt;包过滤防火墙配置规则&lt;/h3&gt;
&lt;p&gt;对于包过滤防火墙，需要配置一套说明匹配条件的指令。其中每个规则通常包含模式匹配条件(pattern-matching criteria)和对应的动作(action)（很像Gateway里面的&lt;strong&gt;断言&lt;/strong&gt;），匹配条件通常是包字段值，例如源/目的IP地址、端口号等。&lt;/p&gt;
&lt;p&gt;当一个数据包到达时，就会在&lt;strong&gt;ACL&lt;/strong&gt;中按照顺序匹配条件，第一个匹配的规则执行相应的动作。比较常见的动作有阻止或加速相应流量、调整计数器、写入日志等**（AOP思想）**。&lt;/p&gt;
&lt;h3 id=&#34;iptables&#34;&gt;iptables&lt;/h3&gt;
&lt;p&gt;iptables是Linux中用来构建防火墙系统的，它能够提供无状态和有状态的包过滤，以及支持NAT和NAPT。&lt;/p&gt;
&lt;p&gt;iptables包含&lt;strong&gt;过滤表格(table)&lt;strong&gt;和&lt;/strong&gt;过滤链(chain)&lt;/strong&gt;，一个表格包括多个预定义的链，或者多个自定义的链。iptables有三个预定义的表格：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;filter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用来处理基本的包过滤，包括INPUT、FORWARD和OUTPUT三条过滤链，分别对应于目的地是防火墙路由器本身运行程序的流量、路由时通过防火墙的流量、从该防火墙主机出发的流量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nat&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包含了PREROUTING、OUTPUT和POSTROUTING三条过滤链。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mangle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包含了五条链，主要用于任意修改数据包。&lt;/p&gt;
&lt;p&gt;每条过滤链是一个规则列表，每条规则是匹配条件和对应的动作，包括：ACCEPT（转发）、DROP（丢弃）、QUEUE（将数据包交给程序处理）、RETURN（在之前出发的一条链中继续，即返还该包），以及其他自定义的动作。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;p&gt;《TCP/IP详解 卷1:协议》&lt;/p&gt;
&lt;p&gt;《图解TCP/IP》&lt;/p&gt;
</description>
        </item>
        <item>
        <title>全文索引详解（基于InnoDB引擎）</title>
        <link>https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/</link>
        <pubDate>Sun, 06 Mar 2022 17:20:33 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/</guid>
        <description>&lt;p&gt;&lt;em&gt;注：以下部分内容来自《MySQL技术内幕：InnoDB存储引擎》，以及我个人的一些理解和引申。如有侵权，请联系我删除，谢谢！&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;为什么需要全文索引&#34;&gt;&lt;strong&gt;为什么需要全文索引&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;我们都知道，InnoDB中主要使用B+树作为索引（以及少量的哈希索引，主要是&lt;strong&gt;自适应哈希&lt;/strong&gt;）。根据B+树的特点，我们可以在有索引的情况下，使用索引的前缀进行查找，例如，检索以“Covid”作为标题开头的疫情新闻：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LIKE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid%&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这是可以实现的。（注意，这里和索引的&lt;strong&gt;最左匹配原则&lt;/strong&gt;没有关系。由于LIKE关键字，这里使用的是范围查询，而最左匹配原则在遇到范围查询时无效。）&lt;/p&gt;
&lt;p&gt;然而当我们需要将查询的关键字不在字段的开头（更多情况下的确是这样），那么我们的B+树索引就无法奏效了，例如，检索标题包含“Covid”的疫情新闻：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LIKE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;%Covid%&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;那么这时，就需要全文索引了。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;全文索引&#34;&gt;全文索引&lt;/h2&gt;
&lt;h3 id=&#34;定义&#34;&gt;定义&lt;/h3&gt;
&lt;p&gt;书上是这样定义全文索引的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;全文索引（Full-Text Search）是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种分析和统计。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;讲的很清楚。&lt;/p&gt;
&lt;h3 id=&#34;inverted-index倒排索引&#34;&gt;Inverted Index（倒排索引）&lt;/h3&gt;
&lt;p&gt;之前一直听过倒排索引（比如ElasticSearch里面），读完书才发现，倒排索引实际上是全文索引的一种常见的实现。它的概念和B+树的索引是等级的。&lt;/p&gt;
&lt;p&gt;倒排索引有两种具体的表现形式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inverted File Index，表现形式为（单词，单词所在文档ID）&lt;/li&gt;
&lt;li&gt;Full Inverted Index，表现形式为（单词，（单词所在文档ID，具体位置））&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，二者的差别主要是后者多存储了一个文档中的具体位置，虽然需要维护额外的存储空间，但也更方便我们迅速找到相应的具体段落。InnoDB中的实现也是基于后者的。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;innodb的实现&#34;&gt;InnoDB的实现&lt;/h2&gt;
&lt;p&gt;InnoDB从1.2.x版本开始支持全文索引。&lt;/p&gt;
&lt;h3 id=&#34;auxiliary-table辅助表&#34;&gt;Auxiliary Table（辅助表）&lt;/h3&gt;
&lt;p&gt;作为索引，肯定需要空间进行存储。对于全文索引来说，存储索引的地方即是&lt;strong&gt;Auxiliary Table&lt;/strong&gt;，即辅助表，一般是用关联数组实现的。InnoDB中的辅助表有两列，分别为&lt;strong&gt;word&lt;/strong&gt;字段和&lt;strong&gt;ilist&lt;/strong&gt;字段，在word字段上设有索引。而ilist，则是前面提到的（文档ID，位置），用来迅速定位。&lt;/p&gt;
&lt;p&gt;在InnoDB中，一共有&lt;strong&gt;六张&lt;/strong&gt;辅助表（为了提高并发性能），每张表根据word的Latin编码进行分区。并且，辅助表持久化在磁盘上。&lt;/p&gt;
&lt;h3 id=&#34;fts-index-cache全文检索索引缓存&#34;&gt;FTS Index Cache（全文检索索引缓存）&lt;/h3&gt;
&lt;p&gt;正如其名，FTS Index Cache作为cache，目的非常单纯，就是为了&lt;strong&gt;提高检索性能&lt;/strong&gt;；采用&lt;strong&gt;红黑树&lt;/strong&gt;实现，根据（word，ilist）进行排序。&lt;/p&gt;
&lt;h4 id=&#34;为什么是红黑树&#34;&gt;为什么是红黑树？&lt;/h4&gt;
&lt;p&gt;书上没有说，我去翻了官方文档也没有具体说明。但其实根据它的特点，我们不难推出：&lt;/p&gt;
&lt;p&gt;FTS Index Cache是存储在&lt;strong&gt;内存&lt;/strong&gt;中的（in-memory）。红黑树相较于AVL树，由于在插入/删除的情况下需要的调整代价更小，所以在面对频繁的删改（这里也是同样）时性能更优。而我们知道，InnoDB使用B+树作为索引结构主要是因为索引存储在磁盘上，为了尽量减少磁盘IO，需要树的高度尽可能低。但是在内存中，没有磁盘IO的限制，红黑树显然具有更大的优势。&lt;/p&gt;
&lt;p&gt;其实，基于在内存中这一前提，很多设计都选择了红黑树，epoll、JDK8的HashMap，由果溯因，也看得出红黑树效率是很高的。&lt;/p&gt;
&lt;h4 id=&#34;和change-buffer对比&#34;&gt;和Change Buffer对比&lt;/h4&gt;
&lt;p&gt;我们知道InnoDB中很多地方使用了缓存，而&lt;strong&gt;Change Buffer&lt;/strong&gt;可以很好的与FTS Index Cache进行类比：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于Change Buffer，每次写入都不立刻持久化到磁盘上（不然也就失去了作为buffer的意义），而往往等到记录的数据页被读入内存中，再进行相应的修改；&lt;/li&gt;
&lt;li&gt;而对于FTS Index Cache也是同样：当对全文检索进行查询时，FTS Index Cache的word字段才被合并到辅助表中，然后再进行查询。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么这样一来，一定会有一个问题：当数据库宕机时，部分FTS Index Cache的数据可能还没有被写入辅助表中。为了解决这个问题，书上是这样描述的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那么下次重启数据库时，当用户对表进行全文检索（查询或者插入操作）时，InnoDB存储引擎会自动读取未完成的文档，然后进行分词操作，再将分词的结果放入到FTS Index Cache中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;说白了，就是保留上次的状态，类似于HTTP“断点续传”的功能。但是HTTP断点续传基于头部的range字段，而这里重新开始又基于什么呢？关于这一点，书上并没有给出明确的答复，但是我想，可以通过Redis中相似的操作，进行合理的推论：&lt;/p&gt;
&lt;p&gt;我们知道，Redis中对过期键采取的删除策略是惰性删除和定期删除。其中定期删除的实现由serverCron函数调用activeExpireCycle函数，在规定时间内遍历各个数据库。它内部维护了一个current_db的全局变量，记录当前函数的检查进度。如果此时遍历结束但没有遍历完，下一次再开始时就会从current_db标识的数据库开始，而不是从头开始。&lt;/p&gt;
&lt;p&gt;那么类比一下，这里对于FTS Index Cache的遍历写入就相当于对数据库中过期键的遍历检查。那么，和current_db相同，InnoDB应该也是维护了一个&lt;strong&gt;全局变量&lt;/strong&gt;（当然，肯定需要持久化到磁盘上），记录当前写入的进度，从而使得下次重启时，能够续着上一次的进度进行写入。&lt;/p&gt;
&lt;h3 id=&#34;fts-document-id&#34;&gt;FTS Document ID&lt;/h3&gt;
&lt;p&gt;如果光凭借辅助表中的word和ilist，我们无法直接将需要进行搜索的文本与辅助表进行联系。而&lt;strong&gt;FTS Document ID&lt;/strong&gt;帮助我们完成了这项工作。它的作用，即是在数据表中，和word进行映射。&lt;/p&gt;
&lt;p&gt;在InnoDB中，这一列被命名为FTS_DOC_ID，类型必须为&lt;strong&gt;BIGINT UNSIGNED NOT NULL&lt;/strong&gt;。我们不妨测试一下，自己建一个含有名为FTS_DOC_ID，类型不满足要求的列，不出意外报错：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[42000][1166] Incorrect column name &amp;#39;FTS_DOC_ID&amp;#39;.
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们当然可以手动创建这一列（只要满足类型要求），如果没有手动创建，InnoDB也会为我们自动生成。&lt;/p&gt;
&lt;p&gt;此外，在对文档中的分词进行删除时，InnoDB将不会删除辅助表中的记录，而是只删除FTS Index Cache中的记录，并且将被删除记录的FTS_DOC_ID保存在DELETED auxiliary table中。至于为什么不删除，官方文档做了很好的解释：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/ftindex.png&#34;
	width=&#34;2360&#34;
	height=&#34;422&#34;
	srcset=&#34;https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/ftindex_hucb4517e2464f1b3a73a8c3833b3e3350_253752_480x0_resize_box_3.png 480w, https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/ftindex_hucb4517e2464f1b3a73a8c3833b3e3350_253752_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;全文索引的删除&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;559&#34;
		data-flex-basis=&#34;1342px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;意思就是说对于全文索引进行删除时，会导致辅助表中非常多的细微的改动，也就影响了对于这些表的并发访问。 所以，不对表中数据做真实删改，而是通过将FTS_DOC_ID保存在DELETED auxiliary table中，很好的避免了这个问题。&lt;/p&gt;
&lt;p&gt;实际上，类似的“&lt;strong&gt;懒删除&lt;/strong&gt;”策略在很多地方都有应用，例如Redis中，对于过期键删除采用的策略之一就是惰性删除；对于执行sdstrim之后的SDS也采用了惰性空间释放。&lt;/p&gt;
&lt;p&gt;当然，一直不删除，无效的数据始终堆积在辅助表中，会让表变得非常庞大，占据额外的空间。此时我们就可以通过&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;n&#34;&gt;OPTIMIZE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;来进行删除操作。当然，OPTIMIZE TABLE还有别的一些功能，例如&lt;strong&gt;重新统计基数&lt;/strong&gt;，由于和本文关系不大，这里就不展开了。&lt;/p&gt;
&lt;h3 id=&#34;stopword-list&#34;&gt;Stopword List&lt;/h3&gt;
&lt;p&gt;顾名思义，就是维护了一张表，对于表中的词（大多是没有太大意义的）不进行索引。具体的表在information_schema下的INNODB_FT_DEFAULT_STOPWORD。&lt;/p&gt;
&lt;h3 id=&#34;其他限制&#34;&gt;其他限制&lt;/h3&gt;
&lt;p&gt;书上还列举了当前InnoDB的全文检索的限制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每张表只能有一个全文检索的索引&lt;/li&gt;
&lt;li&gt;由多列组合而成的全文检索的索引列必须使用相同的字符集与排序规则&lt;/li&gt;
&lt;li&gt;不支持没有单词界定符（delimiter）的语言，如中文、日文、韩语等&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;使用全文检索&#34;&gt;使用全文检索&lt;/h2&gt;
&lt;p&gt;InnoDB中，使用全文索引的进行检索的方式为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expr&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;search_modifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中，MATCH指定需要查询的列，AGAINST指定查询方法，有以下三种。&lt;/p&gt;
&lt;h3 id=&#34;natural-language&#34;&gt;Natural Language&lt;/h3&gt;
&lt;p&gt;查询带有指定词的文档，例如查询新闻标题中带有“Covid”的行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NATURAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LANGUAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这一种方法也是InnoDB默认的方法，因而可以简写：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查询返回的结果根据相关性进行降序排序。相关性是一个非负浮点数，计算依据于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;word是否在文档中出现&lt;/li&gt;
&lt;li&gt;word在文档中出现的次数&lt;/li&gt;
&lt;li&gt;word在索引列中的数量&lt;/li&gt;
&lt;li&gt;多少个文档包含该word&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，查询的word长度也需要在[innodb_ft_min_token_size, innodb_ft_max_token_size]之间，默认值分别为3和84。&lt;/p&gt;
&lt;h3 id=&#34;boolean&#34;&gt;Boolean&lt;/h3&gt;
&lt;p&gt;Boolean模式会允许对查询的word进行符号拼接，规则如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;+ 表示该word必须存在；- 相反&lt;/li&gt;
&lt;li&gt;无操作符表示该word可选，如出现则相关性更高&lt;/li&gt;
&lt;li&gt;@distance表示查询的多个单词距离是否在distance之内，单位为字节&lt;/li&gt;
&lt;li&gt;&amp;gt; 表示该word出现时增加相关性； &amp;lt; 相反&lt;/li&gt;
&lt;li&gt;~ 表示该word出现时相关性为负&lt;/li&gt;
&lt;li&gt;* 表示以该单词开头的单词&lt;/li&gt;
&lt;li&gt;&amp;quot; 表示短语&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如查询新闻标题中带有“Covid”但没有“Today”的行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;+Covid -Today&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;BOOLEAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;query-expansion&#34;&gt;Query Expansion&lt;/h3&gt;
&lt;p&gt;查询扩展，我的理解是进行二次查询。当条件有限时比较有用。查询分为两个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据搜索的word进行全文索引查询&lt;/li&gt;
&lt;li&gt;根据第一阶段产生的分词，再进行一次全文索引的查询&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如，先通过NATURAL LANGUAGE模式查询新闻标题中带有“Covid”的行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NATURAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LANGUAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;之后再使用QUERY EXPANSION进行查询，得到的结果就是与第一步结果相关的，而非仅仅满足条件的。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>《MySQL技术内幕》读书笔记（1）</title>
        <link>https://example.com/p/innodb_book_1/</link>
        <pubDate>Sun, 06 Mar 2022 16:59:40 +0800</pubDate>
        
        <guid>https://example.com/p/innodb_book_1/</guid>
        <description>&lt;p&gt;2.4 CheckPoint，讲到了CheckPoint解决的问题，其中第三点是“重做日志不可用时，刷新脏页”。详细的描述是这样的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分的重做日志，因此这部分就可以被覆盖重用。&lt;strong&gt;若此时重做日志还需要使用，那么必须强制产生CheckPoint，将缓冲池中的页至少刷新到当前重做日志的位置。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;读到这一段的时候，尤其是加粗部分的内容，我不禁产生疑惑：缓冲池中的页不是本来就和redolog状态相同吗？为什么还需要将缓冲池中的页刷新？&lt;/p&gt;
&lt;p&gt;第二天回顾的时候，我思考了一下。&lt;strong&gt;（以下为是个人解读，如有错误欢迎批评指正）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先，由于InnoDB采用WAL搭配redolog保证crash safe，也就是更新数据的时候，先写redolog，再写buffer pool中的数据页。又由于写redolog时需要先写redolog buffer，而这个过程由于&lt;strong&gt;不需要doublewrite&lt;/strong&gt;，应该是比较快的。所以，这就可能导致在数据量大、并发写多的情况下，很多操作都被写到了redolog中，但还没有写到buffer pool中的数据页中，如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/innodb_book_1/redolog&amp;amp;bfpool.jpeg&#34;
	width=&#34;3277&#34;
	height=&#34;999&#34;
	srcset=&#34;https://example.com/p/innodb_book_1/redolog&amp;amp;bfpool_hu9b47d580dc76ef093ae3038fc81ae849_273298_480x0_resize_q75_box.jpeg 480w, https://example.com/p/innodb_book_1/redolog&amp;amp;bfpool_hu9b47d580dc76ef093ae3038fc81ae849_273298_1024x0_resize_q75_box.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;redolog和buffer pool对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;328&#34;
		data-flex-basis=&#34;787px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;而这时，由于redolog是循环写，在空间不足时（写不下了），就产生了书上说的“不可用”状态。&lt;/p&gt;
&lt;p&gt;因此此时，必须强制先将buffer pool中的数据页写入一部分（刷回盘），和redolog保持一致，从而腾出空间。具体的解决措施，即是属于Fuzzy CheckPoint的Async/Sync Flush CheckPoint，根据checkpoint_age，分别和async_water_mark以及sync_water_mark比较，选择相应的Flush操作。具体判断过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当checkpoint_age &amp;lt; async_water_mark时，无需刷页&lt;/li&gt;
&lt;li&gt;当async_water_mark &amp;lt; checkpoint_age &amp;lt; sync_water_mark时，触发Async Flush&lt;/li&gt;
&lt;li&gt;当sync_water_mark &amp;lt; checkpoint_age时，触发Sync Flush（一般很少发生）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，water_mark的计算公式为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;async_water_mark = 75% * total_redo_log_file_size&lt;/p&gt;
&lt;p&gt;sync_water_mark = 90% * total_redo_log_file_size&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;而checkpoint_age的计算公式为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;checkpoint_age = redo_lsn - checkpoint_lsn&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;LSN即Log Sequence Number，我的理解里，其实就和kafka里的offset作用差不多。&lt;/p&gt;
&lt;p&gt;经过Flush操作之后，确保checkpoint_age &amp;lt; async_water_mark。&lt;/p&gt;
&lt;p&gt;回到刚才的问题，所以，文中的“不可用”，指的应该是&lt;strong&gt;redolog写空间不足&lt;/strong&gt;。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>OpenFeign远程服务调用返回结果时报错 ClassCastException</title>
        <link>https://example.com/p/openfeign%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E6%97%B6%E6%8A%A5%E9%94%99-classcastexception/</link>
        <pubDate>Sun, 06 Mar 2022 16:54:56 +0800</pubDate>
        
        <guid>https://example.com/p/openfeign%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E6%97%B6%E6%8A%A5%E9%94%99-classcastexception/</guid>
        <description>&lt;p&gt;一开始挺纳闷，我也返回的结果怎么会是LinkedHashMap呢？我代码里也没有用LinkedHashMap封装结果呀？&lt;/p&gt;
&lt;p&gt;上网搜了一下发现：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;​    因为rpc远程调用在底层还是使用的HTTPClient，所以在传递参数的时候，必定要有个顺序，当你传递map的时候map里面的值也要有顺序，不然服务层在接的时候就出问题了，所以它才会从map转为linkedhashMap！spring 有一个类叫ModelMap，继承了linkedhashMap public class ModelMap extends LinkedHashMap ,所以一个接口返回的结果就可以直接用ModelMap来接，注意ModelMap是没有泛型的，不管你返回的结果是什么类型的map，泛型是多复杂的map，都可以直接new一个Modelmap，用它来接返回的结果！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;原文出处：&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/hp_yangpeng/article/details/80592332?ops_request_misc=%7B%22request%5Fid%22%3A%22163915388716780274112741%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;amp;request_id=163915388716780274112741&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-80592332.pc_search_result_cache&amp;amp;utm_term=feign&amp;#43;%e8%bf%94%e5%9b%9elinkedhashmap&amp;amp;spm=1018.2226.3001.4187&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;spring cloud远程调用接口返回linkedHashMap问题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原来是这样。了解了原因之后，写个结果转换工具类：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ConvertUtil&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

    &lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * 获取指定类对象
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * @param result 远程调用结果
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * @param targetClassInstance 指定类对象实例
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * @return
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     */&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;getFeignResult&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targetClassInstance&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;ObjectMapper&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mapper&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ObjectMapper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 通过ObjectMapper获取映射
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;Class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targetClass&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;forName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;targetClassInstance&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getClass&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 获取指定对象类
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mapper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;convertValue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targetClass&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
        &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;catch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ClassNotFoundException&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;printStackTrace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
        &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;需要转换的时候，调用即可：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;Student&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;res&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Student&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConvertUtil&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getFeignResult&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;studentService&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;loginByPassword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dto&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Student&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
